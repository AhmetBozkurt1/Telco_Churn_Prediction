{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahmetbozkurt/anaconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import optuna\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report, RocCurveDisplay\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################### Shape #####################\n",
      "(7043, 21)\n",
      "##################### Types #####################\n",
      "customerID           object\n",
      "gender               object\n",
      "SeniorCitizen         int64\n",
      "Partner              object\n",
      "Dependents           object\n",
      "tenure                int64\n",
      "PhoneService         object\n",
      "MultipleLines        object\n",
      "InternetService      object\n",
      "OnlineSecurity       object\n",
      "OnlineBackup         object\n",
      "DeviceProtection     object\n",
      "TechSupport          object\n",
      "StreamingTV          object\n",
      "StreamingMovies      object\n",
      "Contract             object\n",
      "PaperlessBilling     object\n",
      "PaymentMethod        object\n",
      "MonthlyCharges      float64\n",
      "TotalCharges         object\n",
      "Churn                object\n",
      "dtype: object\n",
      "##################### Head #####################\n",
      "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService     MultipleLines InternetService OnlineSecurity OnlineBackup DeviceProtection TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling     PaymentMethod  MonthlyCharges TotalCharges Churn\n",
      "0  7590-VHVEG  Female              0     Yes         No       1           No  No phone service             DSL             No          Yes               No          No          No              No  Month-to-month              Yes  Electronic check          29.850        29.85    No\n",
      "1  5575-GNVDE    Male              0      No         No      34          Yes                No             DSL            Yes           No              Yes          No          No              No        One year               No      Mailed check          56.950       1889.5    No\n",
      "2  3668-QPYBK    Male              0      No         No       2          Yes                No             DSL            Yes          Yes               No          No          No              No  Month-to-month              Yes      Mailed check          53.850       108.15   Yes\n",
      "##################### Tail #####################\n",
      "      customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService     MultipleLines InternetService OnlineSecurity OnlineBackup DeviceProtection TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling              PaymentMethod  MonthlyCharges TotalCharges Churn\n",
      "7040  4801-JZAZL  Female              0     Yes        Yes      11           No  No phone service             DSL            Yes           No               No          No          No              No  Month-to-month              Yes           Electronic check          29.600       346.45    No\n",
      "7041  8361-LTMKD    Male              1     Yes         No       4          Yes               Yes     Fiber optic             No           No               No          No          No              No  Month-to-month              Yes               Mailed check          74.400        306.6   Yes\n",
      "7042  3186-AJIEK    Male              0      No         No      66          Yes                No     Fiber optic            Yes           No              Yes         Yes         Yes             Yes        Two year              Yes  Bank transfer (automatic)         105.650       6844.5    No\n",
      "##################### NA #####################\n",
      "customerID          0\n",
      "gender              0\n",
      "SeniorCitizen       0\n",
      "Partner             0\n",
      "Dependents          0\n",
      "tenure              0\n",
      "PhoneService        0\n",
      "MultipleLines       0\n",
      "InternetService     0\n",
      "OnlineSecurity      0\n",
      "OnlineBackup        0\n",
      "DeviceProtection    0\n",
      "TechSupport         0\n",
      "StreamingTV         0\n",
      "StreamingMovies     0\n",
      "Contract            0\n",
      "PaperlessBilling    0\n",
      "PaymentMethod       0\n",
      "MonthlyCharges      0\n",
      "TotalCharges        0\n",
      "Churn               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Veri Seti Okutma\n",
    "df = pd.read_csv(\"Telco-Customer-Churn.csv\")\n",
    "def check_df(dataframe):\n",
    "    print(\"##################### Shape #####################\")\n",
    "    print(dataframe.shape)\n",
    "    print(\"##################### Types #####################\")\n",
    "    print(dataframe.dtypes)\n",
    "    print(\"##################### Head #####################\")\n",
    "    print(dataframe.head(3))\n",
    "    print(\"##################### Tail #####################\")\n",
    "    print(dataframe.tail(3))\n",
    "    print(\"##################### NA #####################\")\n",
    "    print(dataframe.isnull().sum())\n",
    "check_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri setinde Type hatası olan değişkenleri düzeltelim.\n",
    "df.columns = [col.title() for col in df.columns]\n",
    "# Aslında numerik olan değişken object onu düzenleyelim.\n",
    "df[\"Totalcharges\"] = pd.to_numeric(df[\"Totalcharges\"], errors=\"coerce\")\n",
    "# Target değişkeni numeric hale getirelim.\n",
    "df[\"Churn\"] = df[\"Churn\"].apply(lambda x: 1 if x == \"Yes\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations: 7043\n",
      "Variables: 21\n",
      "cat_cols: 17\n",
      "num_cols: 3\n",
      "cat_but_car: 1\n",
      "num_but_cat: 2\n"
     ]
    }
   ],
   "source": [
    "# Değişkenleri Sınıflandıralım.\n",
    "def grab_col_names(dataframe, cat_th=10, car_th=20):\n",
    "    \"\"\"\n",
    "    Veri setindeki kategorik,numerik ve kategorik fakat kardinal değişkenlerin isimlerini verir.\n",
    "    Not: Kategorik değişkenlerin içerisine numerik görünümlü kategorik değişkenler de dahildir\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe: dataframe\n",
    "        Değişken isimleri alınmak istenen dataframe'dir\n",
    "    cat_th: int, float\n",
    "        Numerik fakat kategorik değişkenler için sınıf eşik değeri\n",
    "    car_th: int, float\n",
    "        Kategorik fakat kardinal değişkenlerin sınıf eşik değeri\n",
    "\n",
    "      Returns\n",
    "    ------\n",
    "        cat_cols: list\n",
    "                Kategorik değişken listesi\n",
    "        num_cols: list\n",
    "                Numerik değişken listesi\n",
    "        cat_but_car: list\n",
    "                Kategorik görünümlü kardinal değişken listesi\n",
    "\n",
    "    Examples\n",
    "    ------\n",
    "        import seaborn as sns\n",
    "        df = sns.load_dataset(\"iris\")\n",
    "        print(grab_col_names(df))\n",
    "\n",
    "\n",
    "    Notes\n",
    "    ------\n",
    "        cat_cols + num_cols + cat_but_car = toplam değişken sayısı\n",
    "        num_but_cat cat_cols'un içerisinde.\n",
    "        Return olan 3 liste toplamı toplam değişken sayısına eşittir: cat_cols + num_cols + cat_but_car = değişken sayısı\n",
    "    \"\"\"\n",
    "\n",
    "    # cat_cols, cat_but_car\n",
    "    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n",
    "    num_but_cat = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\" and dataframe[col].nunique() < cat_th]\n",
    "    cat_but_car = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\" and dataframe[col].nunique() > car_th]\n",
    "    cat_cols = cat_cols + num_but_cat\n",
    "    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n",
    "\n",
    "    # num_cols\n",
    "    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n",
    "    num_cols = [col for col in num_cols if col not in num_but_cat]\n",
    "\n",
    "    print(f\"Observations: {dataframe.shape[0]}\")\n",
    "    print(f\"Variables: {dataframe.shape[1]}\")\n",
    "    print(f'cat_cols: {len(cat_cols)}')\n",
    "    print(f'num_cols: {len(num_cols)}')\n",
    "    print(f'cat_but_car: {len(cat_but_car)}')\n",
    "    print(f'num_but_cat: {len(num_but_cat)}')\n",
    "    return cat_cols, num_cols, cat_but_car\n",
    "cat_cols, num_cols, cat_but_car = grab_col_names(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Gender  Ratio\n",
      "Gender               \n",
      "Male      3555 50.476\n",
      "Female    3488 49.524\n",
      "##########################################\n",
      "         Partner  Ratio\n",
      "Partner                \n",
      "No          3641 51.697\n",
      "Yes         3402 48.303\n",
      "##########################################\n",
      "            Dependents  Ratio\n",
      "Dependents                   \n",
      "No                4933 70.041\n",
      "Yes               2110 29.959\n",
      "##########################################\n",
      "              Phoneservice  Ratio\n",
      "Phoneservice                     \n",
      "Yes                   6361 90.317\n",
      "No                     682  9.683\n",
      "##########################################\n",
      "                  Multiplelines  Ratio\n",
      "Multiplelines                         \n",
      "No                         3390 48.133\n",
      "Yes                        2971 42.184\n",
      "No phone service            682  9.683\n",
      "##########################################\n",
      "                 Internetservice  Ratio\n",
      "Internetservice                        \n",
      "Fiber optic                 3096 43.959\n",
      "DSL                         2421 34.375\n",
      "No                          1526 21.667\n",
      "##########################################\n",
      "                     Onlinesecurity  Ratio\n",
      "Onlinesecurity                            \n",
      "No                             3498 49.666\n",
      "Yes                            2019 28.667\n",
      "No internet service            1526 21.667\n",
      "##########################################\n",
      "                     Onlinebackup  Ratio\n",
      "Onlinebackup                            \n",
      "No                           3088 43.845\n",
      "Yes                          2429 34.488\n",
      "No internet service          1526 21.667\n",
      "##########################################\n",
      "                     Deviceprotection  Ratio\n",
      "Deviceprotection                            \n",
      "No                               3095 43.944\n",
      "Yes                              2422 34.389\n",
      "No internet service              1526 21.667\n",
      "##########################################\n",
      "                     Techsupport  Ratio\n",
      "Techsupport                            \n",
      "No                          3473 49.311\n",
      "Yes                         2044 29.022\n",
      "No internet service         1526 21.667\n",
      "##########################################\n",
      "                     Streamingtv  Ratio\n",
      "Streamingtv                            \n",
      "No                          2810 39.898\n",
      "Yes                         2707 38.435\n",
      "No internet service         1526 21.667\n",
      "##########################################\n",
      "                     Streamingmovies  Ratio\n",
      "Streamingmovies                            \n",
      "No                              2785 39.543\n",
      "Yes                             2732 38.790\n",
      "No internet service             1526 21.667\n",
      "##########################################\n",
      "                Contract  Ratio\n",
      "Contract                       \n",
      "Month-to-month      3875 55.019\n",
      "Two year            1695 24.066\n",
      "One year            1473 20.914\n",
      "##########################################\n",
      "                  Paperlessbilling  Ratio\n",
      "Paperlessbilling                         \n",
      "Yes                           4171 59.222\n",
      "No                            2872 40.778\n",
      "##########################################\n",
      "                           Paymentmethod  Ratio\n",
      "Paymentmethod                                  \n",
      "Electronic check                    2365 33.579\n",
      "Mailed check                        1612 22.888\n",
      "Bank transfer (automatic)           1544 21.922\n",
      "Credit card (automatic)             1522 21.610\n",
      "##########################################\n",
      "               Seniorcitizen  Ratio\n",
      "Seniorcitizen                      \n",
      "0                       5901 83.785\n",
      "1                       1142 16.215\n",
      "##########################################\n",
      "       Churn   Ratio\n",
      "Churn               \n",
      "0       7043 100.000\n",
      "##########################################\n"
     ]
    }
   ],
   "source": [
    "# Numerik ve kategorik değişkenlerin veri içindeki dağılımını gözlemleyelim.\n",
    "\n",
    "# Kategorik Değişkenler için:\n",
    "def cat_summary(dataframe, col_name, plot=False):\n",
    "    print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),\n",
    "                        \"Ratio\": 100 * dataframe[col_name].value_counts() / len(dataframe)}))\n",
    "    print(\"##########################################\")\n",
    "    if plot:\n",
    "        sns.countplot(x=dataframe[col_name], data=dataframe)\n",
    "        plt.show(block=True)\n",
    "\n",
    "for col in cat_cols:\n",
    "    cat_summary(df, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerik değişkenler için:\n",
    "def num_summary(dataframe, numerical_col, plot=False):\n",
    "    quantiles = [0.05, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 0.99]\n",
    "    print(dataframe[numerical_col].describe(quantiles).T)\n",
    "\n",
    "    if plot:\n",
    "        dataframe[numerical_col].hist(bins=20)\n",
    "        plt.xlabel(numerical_col)\n",
    "        plt.title(numerical_col)\n",
    "        plt.show(block=True)\n",
    "\n",
    "for col in num_cols:\n",
    "    print(f\"############## {col} ############\")\n",
    "    num_summary(df, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Kategorik değişkenler ile hedef değişken incelemesini yapalım.\n",
    "def target_category(dataframe,  target, col_category):\n",
    "    print(dataframe.groupby(col_category).agg({target: \"mean\"}))\n",
    "    print(\"#\" * 40)\n",
    "\n",
    "for col in cat_cols:\n",
    "    print(f\"######### {col.upper()} #########\")\n",
    "    target_category(df, \"Churn\", col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aykırı Değer İncelemesi Yapalım.\n",
    "def outlier_thresholds(dataframe, col_name, q1=0.01, q3=0.99):\n",
    "    quartile1 = dataframe[col_name].quantile(q1)\n",
    "    quartile3 = dataframe[col_name].quantile(q3)\n",
    "    interquantile_range = quartile3 - quartile1\n",
    "    up_limit = quartile3 + 1.5 * interquantile_range\n",
    "    low_limit = quartile1 - 1.5 * interquantile_range\n",
    "    return low_limit, up_limit\n",
    "def check_outlier(dataframe, col_name):\n",
    "    low, up = outlier_thresholds(dataframe, col_name)\n",
    "    if dataframe.loc[(dataframe[col_name] < low) | (dataframe[col_name] > up)].any(axis=None):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "for col in num_cols:\n",
    "    print(col, check_outlier(df, col))\n",
    "\n",
    "def replace_with_thresholds(dataframe, col_name):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n",
    "    dataframe.loc[dataframe[col_name] > up_limit, col_name] = up_limit\n",
    "    dataframe.loc[dataframe[col_name] < low_limit, col_name] = low_limit\n",
    "\n",
    "# AYKIRI DEĞER YOKTUR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korelasyon İnceleyelim.\n",
    "def corr_map(df, width=14, height=6, annot_kws=15, corr_th=0.7):\n",
    "    corr = df.corr()\n",
    "    cor_matrix = corr.abs()\n",
    "    upper_triangle_matrix = cor_matrix.where(\n",
    "        np.triu(np.ones(cor_matrix.shape), k=1).astype(bool))  # np.bool yerine bool\n",
    "    drop_list = [col for col in upper_triangle_matrix.columns if any(upper_triangle_matrix[col] > corr_th)]\n",
    "    mtx = np.triu(df.corr())\n",
    "    f, ax = plt.subplots(figsize = (width,height))\n",
    "    sns.heatmap(df.corr(),\n",
    "                annot= True,\n",
    "                fmt = \".2f\",\n",
    "                ax=ax,\n",
    "                vmin = -1,\n",
    "                vmax = 1,\n",
    "                cmap = \"RdBu\",\n",
    "                mask = mtx,\n",
    "                linewidth = 0.4,\n",
    "                linecolor = \"black\",\n",
    "                annot_kws={\"size\": annot_kws})\n",
    "    plt.yticks(rotation=0,size=15)\n",
    "    plt.xticks(rotation=75,size=15)\n",
    "    plt.title('\\nCorrelation Map\\n', size = 40)\n",
    "    plt.show()\n",
    "    return drop_list\n",
    "corr_map(df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eksik Gözlem Var mı İnceleyelim.\n",
    "def missing_values_table(dataframe, na_name=False):\n",
    "    na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]\n",
    "    n_miss = dataframe[na_columns].isnull().sum().sort_values(ascending=False)\n",
    "    ratio = (dataframe[na_columns].isnull().sum() / dataframe.shape[0] * 100).sort_values(ascending=False)\n",
    "    missing_df = pd.concat([n_miss, ratio], axis=1, keys=[\"n_miss\", \"ratio\"])\n",
    "    print(missing_df)\n",
    "    if na_name:\n",
    "        return na_columns\n",
    "\n",
    "missing_values_table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Burada eksik değerlere baktık ve anlamlı bir eksiklik mi diye düşündük.Sonunda ise bu eksikliklerin aslında müşterilerin\n",
    "# daha yeni oldukları için boş olduğunu gördük ve bunları \"Monthlycharges\" değişkeni değerleri ile doldurduk.\n",
    "df.loc[df[\"Totalcharges\"].isnull(), \"Totalcharges\"] = df.loc[df[\"Totalcharges\"].isnull(), \"Monthlycharges\"]\n",
    "\n",
    "# Doldurduğumuz değişkenleri kontrol edelim.\n",
    "df.loc[df[\"Tenure\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yeni gelen müşterilerin \"Tenure\" değişkeni 0'dır.Her gözlemin \"Tenure\" değişkenini 1 arttıralım.\n",
    "df[\"Tenure\"] = df[\"Tenure\"] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE MODEL KURULUMU\n",
    "df_base = df.copy()\n",
    "\n",
    "# Encoding İşlemleri\n",
    "def label_encoder(dataframe, binary_col):\n",
    "    labelEncoder = LabelEncoder()\n",
    "    dataframe[binary_col] = labelEncoder.fit_transform(dataframe[binary_col])\n",
    "    return dataframe\n",
    "\n",
    "binary_cols = [col for col in df_base.columns if df_base[col].dtypes == \"O\" and df_base[col].nunique() == 2]\n",
    "for col in binary_cols:\n",
    "    label_encoder(df_base, col)\n",
    "\n",
    "def one_hot_encoder(dataframe, categorical_col, drop_first=True):\n",
    "    dataframe = pd.get_dummies(dataframe, columns=categorical_col, drop_first=drop_first, dtype=int)\n",
    "    return dataframe\n",
    "\n",
    "ohe_cols = [col for col in df_base.columns if df_base[col].dtypes == \"O\" and df_base[col].nunique() > 2 and\n",
    "            col not in \"Customerid\"]\n",
    "\n",
    "df_base = one_hot_encoder(df_base, ohe_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Aşaması\n",
    "X = df_base.drop([\"Customerid\", \"Churn\"], axis=1)\n",
    "y = df_base[\"Churn\"]\n",
    "\n",
    "models = [(\"LR\", LogisticRegression()),\n",
    "          (\"CART\", DecisionTreeClassifier()),\n",
    "          (\"KNN\", KNeighborsClassifier()),\n",
    "          (\"GBM\", GradientBoostingClassifier()),\n",
    "          (\"RF\", RandomForestClassifier()),\n",
    "          (\"XGBoost\", XGBClassifier()),\n",
    "          (\"LightGBM\", LGBMClassifier(verbosity=-1)),\n",
    "          (\"CatBoost\", CatBoostClassifier(verbose=False))]\n",
    "\n",
    "for name, model in models:\n",
    "    cv_results = cross_validate(model, X, y, cv=5, scoring=[\"accuracy\", \"f1\", \"recall\", \"precision\", \"roc_auc\"])\n",
    "    print(f\"########## {name} ##########\")\n",
    "    print(f\"Accuracy: {round(cv_results['test_accuracy'].mean(), 4)}\")\n",
    "    print(f\"Auc: {round(cv_results['test_roc_auc'].mean(), 4)}\")\n",
    "    print(f\"Recall: {round(cv_results['test_recall'].mean(), 4)}\")\n",
    "    print(f\"Precision: {round(cv_results['test_precision'].mean(), 4)}\")\n",
    "    print(f\"F1: {round(cv_results['test_f1'].mean(), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE ENGINEERING\n",
    "\n",
    "# Veri setinde ilk olarak aykırı değer ve eksik değerlere bakalım.\n",
    "missing_values_table(df)  # Eksik değer YOK.\n",
    "# Aykır Değer YOK.\n",
    "for col in num_cols:\n",
    "    print(col, check_outlier(df, col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yeni Değişkenler Üretelim.\n",
    "\n",
    "# Ödeme Yöntemi Otamatik mi?\n",
    "df[\"Pay_Automatic\"] = df[\"Paymentmethod\"].apply(lambda x: 1 if \"automatic\" in x else 0)\n",
    "\n",
    "# Kontrat aylık mı?\n",
    "df[\"Contract_Type\"] = df[\"Contract\"].str.contains(\"Month-to-month\", case=False).astype(int)\n",
    "\n",
    "# Müşterinin yeni olup olmadığının belirlenmesi\n",
    "df.loc[(df[\"Tenure\"] >= 0) & (df[\"Tenure\"] <= 12), \"New_Tenure_Year\"] = \"0-1 Year\"\n",
    "df.loc[(df[\"Tenure\"] > 12) & (df[\"Tenure\"] <= 24), \"New_Tenure_Year\"] = \"1-2 Year\"\n",
    "df.loc[(df[\"Tenure\"] > 24) & (df[\"Tenure\"] <= 36), \"New_Tenure_Year\"] = \"2-3 Year\"\n",
    "df.loc[(df[\"Tenure\"] > 36) & (df[\"Tenure\"] <= 48), \"New_Tenure_Year\"] = \"3-4 Year\"\n",
    "df.loc[(df[\"Tenure\"] > 48) & (df[\"Tenure\"] <= 60), \"New_Tenure_Year\"] = \"4-5 Year\"\n",
    "df.loc[(df[\"Tenure\"] > 60) & (df[\"Tenure\"] <= 72), \"New_Tenure_Year\"] = \"5-6 Year\"\n",
    "df.loc[(df[\"Tenure\"] > 72) & (df[\"Tenure\"] <= float(\"inf\")), \"New_Tenure_Year\"] = \"6+ Year\"\n",
    "\n",
    "# Herhangi bir destek almış mı?\n",
    "df[\"Tech_IsNot\"] = df.apply(lambda x: 1 if (x[\"Onlinesecurity\"] == \"Yes\") or (x[\"Onlinebackup\"] == \"Yes\") or\n",
    "                                           (x[\"Deviceprotection\"] == \"Yes\") or (x[\"Techsupport\"] == \"Yes\") else 0, axis=1)\n",
    "\n",
    "# Aldığı toplam destek sayısı\n",
    "df[\"Total_Tech\"] = df[[\"Onlinesecurity\", \"Onlinebackup\", \"Deviceprotection\", \"Techsupport\"]]. \\\n",
    "    apply(lambda x: (x == \"Yes\").sum(), axis=1)\n",
    "\n",
    "# Aldığı Toplam Hizmet Sayısı\n",
    "df[\"Total_Service\"] = df[[\"Phoneservice\", \"Internetservice\", \"Streamingtv\", \"Streamingmovies\"]]. \\\n",
    "    apply(lambda x: (x == \"Yes\").sum(), axis=1)\n",
    "\n",
    "# Total tutarın aldığı hizmete oranı\n",
    "df[\"Totalcharges_Service\"] = df.apply(lambda x: x[\"Totalcharges\"] / x[\"Total_Service\"] if x[\"Total_Service\"] > 0 \\\n",
    "                                      else x[\"Totalcharges\"], axis=1)\n",
    "\n",
    "# Total tutarın aldığı desteğe oranı\n",
    "df[\"Totalcharges_Tech\"] = df.apply(lambda x: x[\"Totalcharges\"] / x[\"Total_Tech\"] if x[\"Total_Tech\"] > 0 \\\n",
    "                                   else x[\"Totalcharges\"], axis=1)\n",
    "\n",
    "# Yaşlı ve otomatik ödeme\n",
    "df[\"Senior_Automatic\"] = df.apply(lambda x: 1 if (x[\"Seniorcitizen\"] == 1) and (x[\"Pay_Automatic\"] == 0) else 0, axis=1)\n",
    "\n",
    "# Yaşlı ve kontrat tipi\n",
    "df[\"Senior_Contract\"] = df.apply(lambda x: 1 if (x[\"Seniorcitizen\"] == 1) and (x[\"Contract_Type\"] == 1) else 0, axis=1)\n",
    "\n",
    "# Tekrar Değişkenleri sınıflandıralım.\n",
    "cat_cols, num_cols, cat_but_car = grab_col_names(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding İşlemlerini Halledelim.\n",
    "binary_cols = [col for col in df.columns if df[col].dtypes == \"O\" and df[col].nunique() == 2]\n",
    "\n",
    "for col in binary_cols:\n",
    "    label_encoder(df, col)\n",
    "\n",
    "ohe_cols = [col for col in df.columns if df[col].dtypes == \"O\" and df[col].nunique() > 2 and col not in \"Customerid\"]\n",
    "df = one_hot_encoder(df, ohe_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale İşlemleri\n",
    "scale_rs = RobustScaler()\n",
    "df[num_cols] = scale_rs.fit_transform(df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Aşaması\n",
    "X = df.drop([\"Customerid\", \"Churn\"], axis=1)\n",
    "y = df[\"Churn\"]\n",
    "\n",
    "models = [(\"LR\", LogisticRegression()),\n",
    "          (\"CART\", DecisionTreeClassifier()),\n",
    "          (\"KNN\", KNeighborsClassifier()),\n",
    "          (\"GBM\", GradientBoostingClassifier()),\n",
    "          (\"RF\", RandomForestClassifier()),\n",
    "          (\"XGBoost\", XGBClassifier()),\n",
    "          (\"LightGBM\", LGBMClassifier(verbosity=-1)),\n",
    "          (\"CatBoost\", CatBoostClassifier(verbose=False))]\n",
    "\n",
    "for name, model in models:\n",
    "    cv_results = cross_validate(model, X, y, cv=5, scoring=[\"accuracy\", \"f1\", \"recall\", \"precision\", \"roc_auc\"])\n",
    "    print(f\"########## {name} ##########\")\n",
    "    print(f\"Accuracy: {round(cv_results['test_accuracy'].mean(), 4)}\")\n",
    "    print(f\"Auc: {round(cv_results['test_roc_auc'].mean(), 4)}\")\n",
    "    print(f\"Recall: {round(cv_results['test_recall'].mean(), 4)}\")\n",
    "    print(f\"Precision: {round(cv_results['test_precision'].mean(), 4)}\")\n",
    "    print(f\"F1: {round(cv_results['test_f1'].mean(), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model olarak LogisticReg ve GBM ile devam edeceğim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression()\n",
    "# Hiperparametre Optimizasyonu\n",
    "\n",
    "log_param = {'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "             'C': np.logspace(-4, 4, 10),\n",
    "             'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "             'max_iter': [100, 150, 200, 300]}\n",
    "\n",
    "log_model_best_grid = GridSearchCV(log_model, log_param, cv=5, n_jobs=-1, verbose=True).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Model\n",
    "log_final_model = log_model.set_params(**log_model_best_grid.best_params_).fit(X, y)\n",
    "cv_results_final = cross_validate(log_final_model, X, y, cv=5, scoring=[\"accuracy\", \"f1\", \"recall\", \"precision\", \"roc_auc\"])\n",
    "\n",
    "print(f\"Accuracy: {round(cv_results_final['test_accuracy'].mean(), 4)}\")\n",
    "print(f\"Auc: {round(cv_results_final['test_roc_auc'].mean(), 4)}\")\n",
    "print(f\"Recall: {round(cv_results_final['test_recall'].mean(), 4)}\")\n",
    "print(f\"Precision: {round(cv_results_final['test_precision'].mean(), 4)}\")\n",
    "print(f\"F1: {round(cv_results_final['test_f1'].mean(), 4)}\")\n",
    "\n",
    "# Hiperparametre optimizasyonu ile bir şekilde modelimizin başarısını arttırdık."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model olarak GBM'i kullanalım fakat hiperparametre optimizasyonu olarak da OPTUNA kullanalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_model = GradientBoostingClassifier()\n",
    "\n",
    "# Hiperparametre Optimizasyonu(Optuna ile)\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "# Optuna için modelin parametrelerinin belirlendiği fonksiyon\n",
    "def objective(trial):\n",
    "    # Hiperparametre değerlerini belirleyin\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.1)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 8)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 5)\n",
    "    subsample = trial.suggest_float(\"subsample\", 0.5, 1.0)\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 100, 1000)\n",
    "\n",
    "    # Modeli oluşturun ve eğitin\n",
    "    model = GradientBoostingClassifier(\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        subsample=subsample,\n",
    "        n_estimators=n_estimators,\n",
    "        min_samples_split=min_samples_split,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X, y)\n",
    "\n",
    "    cv_results = cross_validate(model, X, y, cv=5,\n",
    "                                scoring=[\"accuracy\"])\n",
    "\n",
    "    accuracy = round(cv_results['test_accuracy'].mean(), 4)\n",
    "    return accuracy\n",
    "\n",
    "# Optuna ile en iyi parametreleri getirecek kod\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(\"En iyi hiperparametreler: \", study.best_params)\n",
    "print(\"En iyi doğruluk skoru: \", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBM Final Model\n",
    "gbm_final_model = gbm_model.set_params(**study.best_params, random_state=42).fit(X, y)\n",
    "cv_results_final = cross_validate(gbm_final_model, X, y, cv=5, scoring=[\"accuracy\", \"f1\", \"recall\", \"precision\", \"roc_auc\"])\n",
    "\n",
    "print(f\"Accuracy: {round(cv_results_final['test_accuracy'].mean(), 4)}\")\n",
    "print(f\"Auc: {round(cv_results_final['test_roc_auc'].mean(), 4)}\")\n",
    "print(f\"Recall: {round(cv_results_final['test_recall'].mean(), 4)}\")\n",
    "print(f\"Precision: {round(cv_results_final['test_precision'].mean(), 4)}\")\n",
    "print(f\"F1: {round(cv_results_final['test_f1'].mean(), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Değişkenlerin önem düzeyini belirten feature_importance fonksiyonunu kullanarak özelliklerin sıralamasını çizdirelim.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Reg için değişken önem düzeyi\n",
    "def plot_importance(model, features, num=len(X), save=False):\n",
    "    feature_imp = pd.DataFrame({\"Value\": model.coef_[0], \"Feature\": features.columns})\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.set(font_scale=1)\n",
    "    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False)[0:num])\n",
    "    plt.title(\"Features\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    if save:\n",
    "        plt.savefig(\"importances.png\")\n",
    "\n",
    "plot_importance(log_final_model, X, num=15)\n",
    "# Oluşturduğumuz \"New_Tenure_Year\" değişkeninin modele çok fazla etki ettiğini görüyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBM için değişken önem düzeyi\n",
    "def plot_importance(model, features, num=len(X), save=False):\n",
    "    feature_imp = pd.DataFrame({\"Value\": model.feature_importances_, \"Feature\": features.columns})\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.set(font_scale=1)\n",
    "    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False)[0:num])\n",
    "    plt.title(\"Features\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    if save:\n",
    "        plt.savefig(\"importances.png\")\n",
    "\n",
    "plot_importance(gbm_final_model, X, num=10)\n",
    "# Oluşturduğumuz değişkenlerin modele etki ettiğini görüyoruz.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
